{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f762b6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\malif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "@st.cache_resource\n",
    "def train_and_save_models(X_train, y_train):\n",
    "    # Weak Model\n",
    "    weak_model = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "    weak_model.fit(X_train, y_train)\n",
    "    with open(\"weak_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(weak_model, f)\n",
    "\n",
    "    # Bagging\n",
    "    bagging_model = BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=None), n_estimators=50, random_state=42\n",
    "    )\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "    with open(\"bagging_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(bagging_model, f)\n",
    "\n",
    "    # AdaBoost\n",
    "    adb_model = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\n",
    "    adb_model.fit(X_train, y_train)\n",
    "    with open(\"adb_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(adb_model, f)\n",
    "\n",
    "    # Gradient Boosting\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    with open(\"gb_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(gb_model, f)\n",
    "\n",
    "    # Stacking\n",
    "    estimators = [(\"dt\", DecisionTreeClassifier(max_depth=1)), (\"svc\", SVC(probability=True))]\n",
    "    stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "    with open(\"stacking_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(stacking_model, f)\n",
    "\n",
    "    # Voting\n",
    "    voting_model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"dt\", DecisionTreeClassifier(max_depth=1)),\n",
    "            (\"rf\", BaggingClassifier(DecisionTreeClassifier(), n_estimators=10)),\n",
    "            (\"svc\", SVC(probability=True))\n",
    "        ],\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "    voting_model.fit(X_train, y_train)\n",
    "    with open(\"voting_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(voting_model, f)\n",
    "\n",
    "    return weak_model, bagging_model, adb_model, gb_model, stacking_model, voting_model\n",
    "\n",
    "import os\n",
    "\n",
    "def load_models():\n",
    "    if all(os.path.exists(fname) for fname in [\n",
    "        \"weak_model.pkl\", \"bagging_model.pkl\", \"adb_model.pkl\",\n",
    "        \"gb_model.pkl\", \"stacking_model.pkl\", \"voting_model.pkl\"\n",
    "    ]):\n",
    "        with open(\"weak_model.pkl\", \"rb\") as f:\n",
    "            weak_model = pickle.load(f)\n",
    "        with open(\"bagging_model.pkl\", \"rb\") as f:\n",
    "            bagging_model = pickle.load(f)\n",
    "        with open(\"adb_model.pkl\", \"rb\") as f:\n",
    "            adb_model = pickle.load(f)\n",
    "        with open(\"gb_model.pkl\", \"rb\") as f:\n",
    "            gb_model = pickle.load(f)\n",
    "        with open(\"stacking_model.pkl\", \"rb\") as f:\n",
    "            stacking_model = pickle.load(f)\n",
    "        with open(\"voting_model.pkl\", \"rb\") as f:\n",
    "            voting_model = pickle.load(f)\n",
    "        return weak_model, bagging_model, adb_model, gb_model, stacking_model, voting_model\n",
    "    else:\n",
    "        return train_and_save_models(X_train, y_train)\n",
    "\n",
    "st.set_page_config(page_title=\"Creative Ensemble Demo\", layout=\"wide\")\n",
    "st.title(\"Creative Ensemble Demo: Weak vs Ensemble Models\")\n",
    "\n",
    "file_path = \"cybersecurity_intrusion_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "target_column = \"attack_detected\"\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == object:\n",
    "        X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "weak_model, bagging_model, adb_model, gb_model, stacking_model, voting_model = load_models()\n",
    "\n",
    "# Sidebar for selecting demonstration mode\n",
    "mode = st.sidebar.selectbox(\"Demo Mode\", [\"Model Comparison\",\"Tricky Packets\", \"Noise Stress Test\", \"Minority Attack Focus\"])\n",
    "\n",
    "\n",
    "if mode == \"Model Comparison\":\n",
    "    st.header(\"Model Comparison: Accuracy, Precision, Recall, F1-Score, Confusion Matrix\")\n",
    "\n",
    "    models = {\n",
    "        \"Weak Tree\": weak_model,\n",
    "        \"Bagging\": bagging_model,\n",
    "        \"AdaBoost\": adb_model,\n",
    "        \"GradientBoosting\": gb_model,\n",
    "        \"Stacking\": stacking_model,\n",
    "        \"Voting\": voting_model\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame to store metrics\n",
    "    metrics_df = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "    for name, model in models.items():\n",
    "        preds = model.predict(X_test)\n",
    "        metrics_df = metrics_df.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": accuracy_score(y_test, preds),\n",
    "            \"Precision\": precision_score(y_test, preds, zero_division=0),\n",
    "            \"Recall\": recall_score(y_test, preds, zero_division=0),\n",
    "            \"F1-Score\": f1_score(y_test, preds, zero_division=0)\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    st.subheader(\"Comparison Table\")\n",
    "    st.dataframe(metrics_df.style.format({\n",
    "        \"Accuracy\": \"{:.2f}\", \"Precision\": \"{:.2f}\", \"Recall\": \"{:.2f}\", \"F1-Score\": \"{:.2f}\"\n",
    "    }))\n",
    "\n",
    "    st.subheader(\"Confusion Matrices\")\n",
    "\n",
    "    # Tabs for confusion matrices\n",
    "    tabs = st.tabs(list(models.keys()))\n",
    "    for tab_name, tab in zip(models.keys(), tabs):\n",
    "        with tab:\n",
    "            st.write(f\"**{tab_name} Confusion Matrix**\")\n",
    "            cm = confusion_matrix(y_test, models[name].predict(X_test))\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(1.8, 1.8), dpi=100)\n",
    "\n",
    "            ax.imshow(cm, cmap=\"Blues\", alpha=0.8)\n",
    "\n",
    "            for i in range(cm.shape[0]):\n",
    "                for j in range(cm.shape[1]):\n",
    "                    ax.text(\n",
    "                        j, i, cm[i, j],\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        fontsize=7\n",
    "                    )\n",
    "\n",
    "            ax.set_xticks([0, 1])\n",
    "            ax.set_yticks([0, 1])\n",
    "            ax.set_xticklabels(le.classes_, fontsize=7)\n",
    "            ax.set_yticklabels(le.classes_, fontsize=7)\n",
    "\n",
    "            ax.set_xlabel(\"Predicted\", fontsize=7)\n",
    "            ax.set_ylabel(\"Actual\", fontsize=7)\n",
    "\n",
    "            plt.tight_layout(pad=0.5)\n",
    "\n",
    "            st.pyplot(fig, use_container_width=False)\n",
    "\n",
    "elif mode == \"Tricky Packets\":\n",
    "    st.header(\"Tricky Packets Demo: Weak Model Fails, Ensembles Succeed\")\n",
    "    num_packets = st.slider(\"Number of tricky packets\", 1, 10, 5)\n",
    "    random_indices = random.sample(range(X_test.shape[0]), num_packets)\n",
    "    X_tricky = X_test[random_indices]\n",
    "    y_tricky = y_test[random_indices]\n",
    "\n",
    "    st.write(\"We modify some features slightly to confuse weak models...\")\n",
    "    X_modified = X_tricky.copy()\n",
    "    noise = np.random.normal(0, 0.5, X_modified.shape)\n",
    "    X_modified += noise\n",
    "\n",
    "    models = {\n",
    "        \"Weak Tree\": weak_model,\n",
    "        \"Bagging\": bagging_model,\n",
    "        \"AdaBoost\": adb_model,\n",
    "        \"GradientBoosting\": gb_model,\n",
    "        \"Stacking\": stacking_model,\n",
    "        \"Voting\": voting_model\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for i in range(num_packets):\n",
    "        row = X_modified[i].reshape(1, -1)\n",
    "        true_label = y_tricky[i]\n",
    "        row_results = {\"True\": true_label}\n",
    "        for name, model in models.items():\n",
    "            pred = model.predict(row)[0]\n",
    "            row_results[name] = pred\n",
    "        results.append(row_results)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    def color_preds(val, true_val):\n",
    "        if val == true_val:\n",
    "            return 'background-color: #b6fcd5'  # green\n",
    "        else:\n",
    "            return 'background-color: #fcb6b6'  # red\n",
    "\n",
    "    st.write(\"Predictions table (green = correct, red = wrong)\")\n",
    "    st.dataframe(df_results.style.apply(lambda x: [color_preds(v, x['True']) for v in x], axis=1))\n",
    "\n",
    "elif mode == \"Noise Stress Test\":\n",
    "    st.header(\"Noise Stress Test: Ensembles vs Weak Model\")\n",
    "    noise_levels = [0, 0.1, 0.2, 0.3, 0.5]\n",
    "    weak_acc = []\n",
    "    bag_acc = []\n",
    "    adb_acc = []\n",
    "    gb_acc = []\n",
    "\n",
    "    for n in noise_levels:\n",
    "        X_noisy = X_test + np.random.normal(0, n, X_test.shape)\n",
    "        weak_acc.append(accuracy_score(y_test, weak_model.predict(X_noisy)))\n",
    "        bag_acc.append(accuracy_score(y_test, bagging_model.predict(X_noisy)))\n",
    "        adb_acc.append(accuracy_score(y_test, adb_model.predict(X_noisy)))\n",
    "        gb_acc.append(accuracy_score(y_test, gb_model.predict(X_noisy)))\n",
    "\n",
    "    st.line_chart({\n",
    "        \"Noise Level\": noise_levels,\n",
    "        \"Weak Model\": weak_acc,\n",
    "        \"Bagging\": bag_acc,\n",
    "        \"AdaBoost\": adb_acc,\n",
    "        \"GradientBoosting\": gb_acc\n",
    "    })\n",
    "\n",
    "elif mode == \"Minority Attack Focus\":\n",
    "    st.header(\"Minority Attack Detection: Ensembles vs Weak Model\")\n",
    "    attack_class = 1  # assuming 1 = attack\n",
    "    weak_preds = weak_model.predict(X_test)\n",
    "    bag_preds = bagging_model.predict(X_test)\n",
    "    adb_preds = adb_model.predict(X_test)\n",
    "    gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "    def attack_detection_rate(y_true, y_pred):\n",
    "        attack_idx = np.where(y_true == attack_class)[0]\n",
    "        return np.mean(y_pred[attack_idx] == attack_class)\n",
    "\n",
    "    st.write(f\"Weak Model Attack Detection Rate: {attack_detection_rate(y_test, weak_preds):.2f}\")\n",
    "    st.write(f\"Bagging Attack Detection Rate: {attack_detection_rate(y_test, bag_preds):.2f}\")\n",
    "    st.write(f\"AdaBoost Attack Detection Rate: {attack_detection_rate(y_test, adb_preds):.2f}\")\n",
    "    st.write(f\"GradientBoosting Attack Detection Rate: {attack_detection_rate(y_test, gb_preds):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
